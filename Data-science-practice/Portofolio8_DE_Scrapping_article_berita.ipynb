{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> SCRAPPING ARTICLE FROM LOCAL WEBSITE </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oleh : Handri Mauludin Maulana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hal pertama yang harus diperhatikan dalam scrapping data dari website adalah website itu sendiri yang akan diambil kode htmlnya.\n",
    "Sebagian website seperti situs resmi tidak dapat dilakukan parsing html secara langsung, hal ini karena situs tersebut \n",
    "terproteksi sangat kuat hingga menyembunyikan kode htmlnya (hidden html), sehingga hal tersebut sangat menyulitkan untuk \n",
    "mengambil datanya. Tetapi pada kasus kali ini, data yang akan diambil adalah artikel berita pada situs lokal website detik.com.\n",
    "Sehingga parsing atau pengambilan data tidak terlalu rumit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests                     #menggunakan package requests dan beautifulsoup untuk scrapping data dari website\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.detik.com/search/searchall?query=KPK'       #situs website yang akan diambil datanya\n",
    "page = requests.get(url)                                       #mendapat feeback request dari website (200: request berhasil)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')              #mengambil kode html website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "berita = soup.findAll('span', {'class' : 'box_text'})          #mencari kode html judul dan tanggal yang terdapat pada span \n",
    "p = 1                                                          # dan kelas box_text\n",
    "tanggal = []\n",
    "judul = []\n",
    "for p in berita:                                               #melakukan iterasi judul dan tanggal yang akan dimasukan ke\n",
    "    dt = p.find(\"span\", {'class': 'date'}).text[16:]           #dalam list\n",
    "    title = p.find(\"h2\", {'class': 'title'}).get_text()\n",
    "    tanggal.append(dt)                                         #list berisi tanggal berita\n",
    "    judul.append(title)                                        #list berisi judul berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = soup.findAll('div', {'class' : 'list media_rows list-berita'})   #mencari situs url pada setiap berita yang berada pada\n",
    "alamat = []                                                             #div dan kelas list media_rows list-berita\n",
    "for p in link:\n",
    "    hrefs = p.find_all('a', href=True)                                  #melakukan iterasi kode url yang akan disimpan ke dalam\n",
    "    for q in hrefs:                                                     #list\n",
    "        alamat.append(q['href'])                                        #list berisi url alamat berita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Mantan Sekjen NasDem Gugat Pasal Suap ke MK ka...   \n",
      "1  KPK Gali Informasi soal Nurdin Abdullah Beli T...   \n",
      "2  HRS Bandingkan Kasus dengan Pinangki-Ary Askha...   \n",
      "3  Pimpinan KPK Akhirnya Penuhi Panggilan Komnas HAM   \n",
      "4  Wakil Ketua KPK Nurul Ghufron Penuhi Panggilan...   \n",
      "\n",
      "                                                 url                tanggal  \n",
      "0  https://news.detik.com/berita/d-5609382/mantan...  17 Jun 2021 12:16 WIB  \n",
      "1  https://news.detik.com/berita/d-5609381/kpk-ga...  17 Jun 2021 12:14 WIB  \n",
      "2  https://news.detik.com/berita/d-5609378/hrs-ba...  17 Jun 2021 12:14 WIB  \n",
      "3  https://news.detik.com/detiktv/d-5609348/pimpi...  17 Jun 2021 11:47 WIB  \n",
      "4  https://news.detik.com/berita/d-5609286/wakil-...  17 Jun 2021 10:54 WIB  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd                                       #membuat list menjadi dataframe\n",
    " \n",
    "column_title = ['title']\n",
    "column_url = ['url']\n",
    "column_tanggal = ['tanggal']\n",
    "title = pd.DataFrame(judul, columns=column_title)                  #dataframe judul berita\n",
    "url = pd.DataFrame(alamat, columns=column_url)                     #dataframe url alamat website\n",
    "tanggal = pd.DataFrame(tanggal, columns=column_tanggal)            #dataframe tanggal berita\n",
    "df = pd.concat([title, url, tanggal], axis=1).reindex(title.index) #menggabungkan dataframe\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                                       #menyimpan dataframe ke dalam bentuk json format\n",
    "\n",
    "with open('solution.json', 'w') as f:             #nama file output berupa solution.json\n",
    "    for x in df.to_dict(orient='r'):\n",
    "        f.write(json.dumps(x) + '\\n')             #isi file menggunakan tab separator antar listnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
